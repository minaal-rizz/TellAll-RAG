# ğŸ§  TellAll RAG System

**TellAll** is an AI-powered document Q&A system built with **FastAPI**, **Gradio**, **LangChain**, **Pinecone**, **MongoDB**, and **Groq LLM**. It enables users to upload documents (PDF, DOCX, PPTX, XLSX), extract and embed their content, ask natural language questions, and get contextual answers with source references.

---

## ğŸ“ Project Structure
```
TellAll_RAG/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ v1/
â”‚   â”‚   â”‚   â”œâ”€â”€ endpoints/              # Versioned route handlers
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ upload.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ask.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ delete.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ docs.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ services/                       # Core service logic
â”‚   â”‚   â”œâ”€â”€ document_service.py
â”‚   â”‚   â”œâ”€â”€ query_service.py
â”‚   â”‚   â”œâ”€â”€ delete_service.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ utilities/                      # Text extraction, reranking, etc.
â”‚   â”‚   â”œâ”€â”€ extractors.py
â”‚   â”‚   â”œâ”€â”€ reranker.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ rag/                            # LangChain integration
â”‚   â”‚   â”œâ”€â”€ langchainn.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ db/                             # Database + vector DB interface
â”‚   â”‚   â”œâ”€â”€ mongo_upload.py
â”‚   â”‚   â”œâ”€â”€ pinecone_upload.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ core/                           # Configuration and clients
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”œâ”€â”€ pinecone_client.py
â”‚   â”‚   â””â”€â”€ mongo_client.py
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app.py                          # Gradio UI frontend
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ .env                                # Secrets and API keys
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
â”œâ”€â”€--main.py                         # FastAPI app entry point

```

---

## ğŸš€ Features

âœ… Upload multiple document types (PDF, DOCX, PPTX, XLSX)  
âœ… Extract and embed content into Pinecone + MongoDB  
âœ… Ask questions through natural language  
âœ… CrossEncoder reranking improves answer quality  
âœ… Groq-powered LLM provides accurate contextual responses  
âœ… Document deletion (single or bulk)  
âœ… Easy Gradio frontend for user interaction

---

## ğŸ› ï¸ Setup Instructions

### 1. Clone the Repo
```bash
git clone https://github.com/minaal-rizz/TellAll-RAG.git
cd TellAll_RAG
```

### 2. Install Dependencies
```bash
pip install -r requirements.txt
```

### 3. Configure `.env`
Create a `.env` file in the root:
```env
MONGO_URI=your-mongo-uri
PINECONE_API_KEY=your-pinecone-key
PINECONE_ENVIRONMENT=your-pinecone-region
PINECONE_INDEX=tellall-index
NAMESPACE=okay
GROQ_API_KEY=your-groq-key
```

### 4. Start the Backend
```bash
uvicorn main:app --reload
```

### 5. Start the Frontend (Gradio)
```bash
python frontend/app.py
```

Access the app at: [http://localhost:7860](http://localhost:7860)

---

## ğŸ§ª API Endpoints
| Method | Endpoint         | Description                     |
|--------|------------------|---------------------------------|
| POST   | `/upload/`       | Upload documents                |
| POST   | `/ask/`          | Ask question (form: `question`) |
| POST   | `/delete/`       | Delete selected files           |
| POST   | `/delete-all/`   | Delete all files                |
| GET    | `/docs/`         | List uploaded documents         |

---

## ğŸ§  RAG Pipeline
1. **Embed query** using SentenceTransformer
2. **Retrieve** chunks from Pinecone
3. **Re-rank** with CrossEncoder
4. **Ask** Groq LLM strictly based on context
5. **Return** answer + references (file/page/slide/sheet info)


---

## âœ¨ Credits
- [FastAPI](https://fastapi.tiangolo.com)
- [LangChain](https://www.langchain.com)
- [Pinecone](https://www.pinecone.io)
- [Groq](https://groq.com)
- [Gradio](https://gradio.app)

---
